{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General Purpose Exp Notebook \n",
    "\n",
    "This notebook has sections to train models, create uncertainty wrappers, and test the models. Experiment specific details are assumed to be contained in `config.py` in the experiment folder below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "EXP_FOLDER = 'taxinet_full'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(EXP_FOLDER))\n",
    "import config # imported from EXP_FOLDER\n",
    "import cProfile\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and save models\n",
    "Trains an ensemble of models as specified in config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model 1 of 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a25eaba93c341a0880b47065c67968b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9df6eddc46a84f3caefb47e39c85644a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=30000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from nn_ood.utils.train import train_ensemble\n",
    "models = train_ensemble(config.N_MODELS, \n",
    "                        config.make_model, \n",
    "                        config.dataset_class, \n",
    "                        config.dist_constructor, \n",
    "                        config.opt_class,\n",
    "                        config.opt_kwargs,\n",
    "                        config.sched_class,\n",
    "                        config.sched_kwargs,\n",
    "                        config.device,\n",
    "                        num_epochs=config.N_EPOCHS,\n",
    "                        batch_size=config.BATCH_SIZE)\n",
    "\n",
    "\n",
    "## SAVE MODEL\n",
    "print(\"saving models\")\n",
    "save_folder = os.path.join(EXP_FOLDER, 'models')\n",
    "if not os.path.exists(save_folder):\n",
    "    os.makedirs(save_folder)\n",
    "\n",
    "for i, model in enumerate(models):\n",
    "    filename = os.path.join(EXP_FOLDER, \"models\", config.FILENAME + \"_%d\" % i)\n",
    "    torch.save(model.state_dict(), filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear memory\n",
    "del models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Data to create uncertainty wrappers\n",
    "Loops over data to create uncertainty wrappers, and saves them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/30000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scod_SRFT_s46_n7\n",
      "<class 'scod.sketching.sketched_pca.SRFT_SinglePassPCA'>\n",
      "computing basis\n",
      "using T = 46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30000/30000 [36:12<00:00, 13.81it/s]\n"
     ]
    }
   ],
   "source": [
    "save_folder = os.path.join(EXP_FOLDER, 'times')\n",
    "if not os.path.exists(save_folder):\n",
    "    os.makedirs(save_folder)\n",
    "    \n",
    "## SET UP MODEL\n",
    "model = config.make_model()\n",
    "\n",
    "## LOAD MODEL\n",
    "filename = os.path.join(EXP_FOLDER, \"models\", config.FILENAME + \"_0\" )\n",
    "model.load_state_dict(torch.load(filename))\n",
    "model = model.to(config.device)\n",
    "model.eval()\n",
    "\n",
    "## SETUP DATASET\n",
    "dataset = config.dataset_class(\"train\", N=5000)\n",
    "\n",
    "## SET UP UNC WRAPPERS\n",
    "for name, info in config.prep_unc_models.items():\n",
    "    print(name)\n",
    "    \n",
    "    config.unfreeze_model(model)\n",
    "    if 'freeze' in info:\n",
    "        if type(info['freeze']) is bool:\n",
    "            freeze_frac = None\n",
    "        else:\n",
    "            freeze_frac = info['freeze']\n",
    "        config.freeze_model(model, freeze_frac=freeze_frac)        \n",
    "    \n",
    "    if 'apply_fn' is info:\n",
    "        model.apply(info['apply_fn'])\n",
    "\n",
    "    unc_model = info['class'](model, config.dist_constructor, info['kwargs'])\n",
    "\n",
    "    cProfile.run(\"\"\"\\n\n",
    "unc_model.process_dataset(dataset)\n",
    "    \"\"\", os.path.join(EXP_FOLDER, \"times\", name+\"_process.timing\") )\n",
    "\n",
    "    filename = os.path.join(EXP_FOLDER, \"models\", name+\"_\"+config.FILENAME)\n",
    "    torch.save(unc_model.state_dict(), filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear memory\n",
    "del model\n",
    "del unc_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Uncertainty Wrappers\n",
    "Evaluates prediction and uncertainty estimate on various datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading models\n",
      "loading model 0\n",
      "loading model 1\n",
      "loading model 2\n",
      "loading model 3\n",
      "loading model 4\n"
     ]
    }
   ],
   "source": [
    "from nn_ood.utils.test import process_datasets\n",
    "\n",
    "# LOAD UNC_WRAPPERS\n",
    "print(\"Loading models\")\n",
    "models = []\n",
    "for i in range(config.N_MODELS):\n",
    "    print(\"loading model %d\" % i)\n",
    "    filename = os.path.join(EXP_FOLDER, 'models', config.FILENAME + \"_%d\" % i)\n",
    "    state_dict = torch.load(filename)\n",
    "    model = config.make_model()\n",
    "    model.load_state_dict(state_dict)\n",
    "    model.eval()\n",
    "    model.to(config.device)\n",
    "    models.append(model)\n",
    "\n",
    "model = models[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test against OoD datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "local_ensemble\n",
      "taxinet_full/models/local_ensemble_model\n",
      "Testing exp1_train\n",
      "1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:14<00:00, 69.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing exp2_train\n",
      "1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:14<00:00, 68.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing exp3_train\n",
      "1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:14<00:00, 67.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing exp4_train\n",
      "1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:14<00:00, 68.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing exp5_train\n",
      "1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:14<00:00, 69.35it/s]\n",
      "/home/apoorva/.virtualenvs/default/lib/python3.6/site-packages/torch/nn/modules/module.py:1025: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kfac_n1_s100\n",
      "taxinet_full/models/kfac_model\n",
      "Testing exp1_train\n",
      "1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1000 [00:00<?, ?it/s]/home/apoorva/.virtualenvs/default/lib/python3.6/site-packages/curvature/sampling.py:43: UserWarning: torch.cholesky is deprecated in favor of torch.linalg.cholesky and will be removed in a future PyTorch release.\n",
      "L = torch.cholesky(A)\n",
      "should be replaced with\n",
      "L = torch.linalg.cholesky(A)\n",
      "and\n",
      "U = torch.cholesky(A, upper=True)\n",
      "should be replaced with\n",
      "U = torch.linalg.cholesky(A).transpose(-2, -1).conj().\n",
      "This transform will produce equivalent results for all valid (symmetric positive definite) inputs. (Triggered internally at  ../aten/src/ATen/native/BatchLinearAlgebra.cpp:1285.)\n",
      "  chol_ifrst = reg_frst.inverse().cholesky()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Cholesky is singular. Using Numpy.\n",
      "PyTorch Cholesky is singular. Using Numpy.\n",
      "PyTorch Cholesky is singular. Using Numpy.\n",
      "PyTorch Cholesky is singular. Using Numpy.\n",
      "PyTorch Cholesky is singular. Using Numpy.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [02:32<00:00,  6.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing exp2_train\n",
      "1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [02:27<00:00,  6.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing exp3_train\n",
      "1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [02:27<00:00,  6.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing exp4_train\n",
      "1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [02:27<00:00,  6.78it/s]\n",
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing exp5_train\n",
      "1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [02:27<00:00,  6.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCOD (T=46,k=7)\n",
      "<class 'scod.sketching.sketched_pca.SinglePassPCA'>\n",
      "taxinet_full/models/scod_SRFT_s46_n7_model\n",
      "Testing exp1_train\n",
      "1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:20<00:00, 48.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing exp2_train\n",
      "1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:20<00:00, 48.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing exp3_train\n",
      "1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:20<00:00, 48.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing exp4_train\n",
      "1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:20<00:00, 48.61it/s]\n",
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing exp5_train\n",
      "1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:20<00:00, 48.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCOD_freeze (k=20)\n",
      "<class 'scod.sketching.sketched_pca.SinglePassPCA'>\n",
      "taxinet_full/models/scod_SRFT_s124_n20_freeze_model\n",
      "Testing exp1_train\n",
      "1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:08<00:00, 118.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing exp2_train\n",
      "1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:08<00:00, 119.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing exp3_train\n",
      "1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:08<00:00, 119.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing exp4_train\n",
      "1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:08<00:00, 118.89it/s]\n",
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing exp5_train\n",
      "1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:08<00:00, 118.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "naive\n",
      "Testing exp1_train\n",
      "1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:03<00:00, 313.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing exp2_train\n",
      "1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:03<00:00, 323.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing exp3_train\n",
      "1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:03<00:00, 319.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing exp4_train\n",
      "1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:03<00:00, 316.21it/s]\n",
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing exp5_train\n",
      "1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:03<00:00, 314.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ensemble\n",
      "Testing exp1_train\n",
      "1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:29<00:00, 34.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing exp2_train\n",
      "1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:28<00:00, 34.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing exp3_train\n",
      "1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:29<00:00, 34.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing exp4_train\n",
      "1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:28<00:00, 34.51it/s]\n",
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing exp5_train\n",
      "1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:29<00:00, 34.22it/s]\n"
     ]
    }
   ],
   "source": [
    "save_folder = os.path.join(EXP_FOLDER, 'results')\n",
    "if not os.path.exists(save_folder):\n",
    "    os.makedirs(save_folder)\n",
    "save_folder = os.path.join(EXP_FOLDER, 'times')\n",
    "if not os.path.exists(save_folder):\n",
    "    os.makedirs(save_folder)\n",
    "    \n",
    "for name, info in config.test_unc_models.items():\n",
    "    print(name)\n",
    "    \n",
    "    config.unfreeze_model(model)\n",
    "    if 'freeze' in info:\n",
    "        if type(info['freeze']) is bool:\n",
    "            freeze_frac = None\n",
    "        else:\n",
    "            freeze_frac = info['freeze']\n",
    "        config.freeze_model(model, freeze_frac=freeze_frac)        \n",
    "    \n",
    "    if 'apply_fn' is info:\n",
    "        model.apply(info['apply_fn'])\n",
    "        \n",
    "    if 'multi_model' in info:\n",
    "        unc_model = info['class'](models, config.dist_constructor, info['kwargs'])\n",
    "    else:\n",
    "        unc_model = info['class'](model, config.dist_constructor, info['kwargs'])\n",
    "    \n",
    "    if info['load_name'] is not None: \n",
    "        filename = os.path.join(EXP_FOLDER, \"models\", info['load_name']+\"_\"+config.FILENAME)\n",
    "        print(filename)\n",
    "        unc_model.load_state_dict(torch.load(filename))\n",
    "        unc_model.cuda()\n",
    "    \n",
    "    try:\n",
    "        cProfile.run(\"\"\"\\n\n",
    "results = process_datasets(config.dataset_class, \n",
    "                           config.test_dataset_args,\n",
    "                           unc_model, \n",
    "                           config.device,\n",
    "                           N=1000,\n",
    "                           **info['forward_kwargs'])\n",
    "        \"\"\", os.path.join(EXP_FOLDER, \"times\", name) )\n",
    "        savepath = os.path.join(EXP_FOLDER, \"results\", name)\n",
    "        torch.save(results, savepath)\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test against noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nn_ood.utils.test import transform_sweep\n",
    "\n",
    "if \"transforms\" not in dir(config):\n",
    "    raise NameError(\"No transforms to test for this experiment\")\n",
    "    \n",
    "save_folder = os.path.join(EXP_FOLDER, 'results_transforms')\n",
    "if not os.path.exists(save_folder):\n",
    "    os.makedirs(save_folder)\n",
    "save_folder = os.path.join(EXP_FOLDER, 'times_transforms')\n",
    "if not os.path.exists(save_folder):\n",
    "    os.makedirs(save_folder)\n",
    "    \n",
    "for name, info in config.test_unc_models.items():\n",
    "    print(name)\n",
    "    \n",
    "    config.unfreeze_model(model)\n",
    "    if 'freeze' in info:\n",
    "        if type(info['freeze']) is bool:\n",
    "            freeze_frac = None\n",
    "        else:\n",
    "            freeze_frac = info['freeze']\n",
    "        config.freeze_model(model, freeze_frac=freeze_frac)        \n",
    "    \n",
    "    if 'apply_fn' is info:\n",
    "        model.apply(info['apply_fn'])\n",
    "        \n",
    "    if 'multi_model' in info:\n",
    "        unc_model = info['class'](models, config.dist_constructor, info['kwargs'])\n",
    "    else:\n",
    "        unc_model = info['class'](model, config.dist_constructor, info['kwargs'])\n",
    "    \n",
    "    if info['load_name'] is not None: \n",
    "        filename = os.path.join(EXP_FOLDER, \"models\", info['load_name']+\"_\"+config.FILENAME)\n",
    "        print(filename)\n",
    "        unc_model.load_state_dict(torch.load(filename))\n",
    "        unc_model.cuda()\n",
    "    \n",
    "\n",
    "    dataset = config.dataset_class(config.in_dist_splits[0],N=1000)\n",
    "    cProfile.run(\"\"\"\\n\n",
    "results = transform_sweep(dataset, \n",
    "                      config.transforms,\n",
    "                      unc_model, \n",
    "                      config.device,\n",
    "                      **info['forward_kwargs'])\n",
    "    \"\"\", os.path.join(EXP_FOLDER, \"times\", name) )\n",
    "    savepath = os.path.join(EXP_FOLDER, \"results\", name)\n",
    "    torch.save(results, savepath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
