{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General Purpose Exp Notebook \n",
    "\n",
    "This notebook has sections to train models, create uncertainty wrappers, and test the models. Experiment specific details are assumed to be contained in `config.py` in the experiment folder below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "EXP_FOLDER = 'cifar10'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(EXP_FOLDER))\n",
    "import config # imported from EXP_FOLDER\n",
    "import cProfile\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and save models\n",
    "Trains an ensemble of models as specified in config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model 1 of 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a25eaba93c341a0880b47065c67968b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9df6eddc46a84f3caefb47e39c85644a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=30000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from nn_ood.utils.train import train_ensemble\n",
    "models = train_ensemble(config.N_MODELS, \n",
    "                        config.make_model, \n",
    "                        config.dataset_class, \n",
    "                        config.dist_constructor, \n",
    "                        config.opt_class,\n",
    "                        config.opt_kwargs,\n",
    "                        config.sched_class,\n",
    "                        config.sched_kwargs,\n",
    "                        config.device,\n",
    "                        num_epochs=config.N_EPOCHS,\n",
    "                        batch_size=config.BATCH_SIZE)\n",
    "\n",
    "\n",
    "## SAVE MODEL\n",
    "print(\"saving models\")\n",
    "save_folder = os.path.join(EXP_FOLDER, 'models')\n",
    "if not os.path.exists(save_folder):\n",
    "    os.makedirs(save_folder)\n",
    "\n",
    "for i, model in enumerate(models):\n",
    "    filename = os.path.join(EXP_FOLDER, \"models\", config.FILENAME + \"_%d\" % i)\n",
    "    torch.save(model.state_dict(), filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear memory\n",
    "del models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Data to create uncertainty wrappers\n",
    "Loops over data to create uncertainty wrappers, and saves them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/5000 [00:00<05:31, 15.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scod_SRFT_s184_n30_freeze_0.85\n",
      "0.85\n",
      "<class 'scod.sketching.sketched_pca.SRFT_SinglePassPCA'>\n",
      "computing basis\n",
      "using T = 184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [03:02<00:00, 27.34it/s]\n",
      "  0%|          | 0/5000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scod_SRFT_s76_n12\n",
      "<class 'scod.sketching.sketched_pca.SRFT_SinglePassPCA'>\n",
      "computing basis\n",
      "using T = 76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [13:41<00:00,  6.09it/s]\n"
     ]
    }
   ],
   "source": [
    "save_folder = os.path.join(EXP_FOLDER, 'times')\n",
    "if not os.path.exists(save_folder):\n",
    "    os.makedirs(save_folder)\n",
    "    \n",
    "## SET UP MODEL\n",
    "model = config.make_model()\n",
    "\n",
    "## LOAD MODEL\n",
    "filename = os.path.join(EXP_FOLDER, \"models\", config.FILENAME + \"_0\" )\n",
    "model.load_state_dict(torch.load(filename))\n",
    "model = model.to(config.device)\n",
    "model.eval()\n",
    "\n",
    "## SETUP DATASET\n",
    "dataset = config.dataset_class(\"train\", N=5000)\n",
    "\n",
    "## SET UP UNC WRAPPERS\n",
    "for name, info in config.prep_unc_models.items():\n",
    "    print(name)\n",
    "    \n",
    "    config.unfreeze_model(model)\n",
    "    if 'freeze' in info:\n",
    "        if type(info['freeze']) is bool:\n",
    "            freeze_frac = None\n",
    "        else:\n",
    "            freeze_frac = info['freeze']\n",
    "        config.freeze_model(model, freeze_frac=freeze_frac)        \n",
    "    \n",
    "    if 'apply_fn' is info:\n",
    "        model.apply(info['apply_fn'])\n",
    "\n",
    "    unc_model = info['class'](model, config.dist_constructor, info['kwargs'])\n",
    "\n",
    "    cProfile.run(\"\"\"\\n\n",
    "unc_model.process_dataset(dataset)\n",
    "    \"\"\", os.path.join(EXP_FOLDER, \"times\", name+\"_process.timing\") )\n",
    "\n",
    "    filename = os.path.join(EXP_FOLDER, \"models\", name+\"_\"+config.FILENAME)\n",
    "    torch.save(unc_model.state_dict(), filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# calibrate hyperparms on val dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "scod_SRFT_s184_n30_freeze_0.85\n",
      "0.85\n",
      "<class 'scod.sketching.sketched_pca.SRFT_SinglePassPCA'>\n",
      "cifar10/models/scod_SRFT_s184_n30_freeze_0.85_model\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2440ad0251fd4ee28f06102480884c56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd54b73f3c4a449982b94b3741357c1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=5000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training complete in 1m 18s\n",
      "Best val Loss: 0.613548\n",
      "[Parameter containing:\n",
      "tensor([-3.7978], device='cuda:0', requires_grad=True)]\n",
      "scod_SRFT_s76_n12\n",
      "<class 'scod.sketching.sketched_pca.SRFT_SinglePassPCA'>\n",
      "cifar10/models/scod_SRFT_s76_n12_model\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d18c03ce90904194ae3bf16c103b3698",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e05fd2fef3464217bfd9888725ce4ca3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=5000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training complete in 7m 34s\n",
      "Best val Loss: 0.620484\n",
      "[Parameter containing:\n",
      "tensor([-9.3006], device='cuda:0', requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "from nn_ood.utils.train import minimize_val_nll\n",
    "\n",
    "save_folder = os.path.join(EXP_FOLDER, 'times')\n",
    "if not os.path.exists(save_folder):\n",
    "    os.makedirs(save_folder)\n",
    "    \n",
    "## SET UP MODEL\n",
    "model = config.make_model()\n",
    "\n",
    "## LOAD MODEL\n",
    "filename = os.path.join(EXP_FOLDER, \"models\", config.FILENAME + \"_0\" )\n",
    "model.load_state_dict(torch.load(filename))\n",
    "model = model.to(config.device)\n",
    "model.eval()\n",
    "\n",
    "## SETUP DATASET\n",
    "dataset = config.dataset_class(\"val\", N=5000)\n",
    "\n",
    "## SET UP UNC WRAPPERS\n",
    "for name, info in config.prep_unc_models.items():\n",
    "    print(name)\n",
    "    \n",
    "    config.unfreeze_model(model)\n",
    "    if 'freeze' in info:\n",
    "        if type(info['freeze']) is bool:\n",
    "            freeze_frac = None\n",
    "        else:\n",
    "            freeze_frac = info['freeze']\n",
    "        config.freeze_model(model, freeze_frac=freeze_frac)        \n",
    "    \n",
    "    if 'apply_fn' is info:\n",
    "        model.apply(info['apply_fn'])\n",
    "\n",
    "    unc_model = info['class'](model, config.dist_constructor, info['kwargs'])\n",
    "    filename = os.path.join(EXP_FOLDER, \"models\", name+\"_\"+config.FILENAME)\n",
    "    print(filename)\n",
    "    unc_model.load_state_dict(torch.load(filename))\n",
    "\n",
    "    try:\n",
    "        hp = unc_model.hyperparameters\n",
    "        minimize_val_nll(unc_model, dataset)\n",
    "        print(unc_model.hyperparameters)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(\"no hyperpameters for this model\")\n",
    "        pass\n",
    "\n",
    "    filename = os.path.join(EXP_FOLDER, \"models\", name+\"_\"+\"calibrated_\"+config.FILENAME)\n",
    "\n",
    "    torch.save(unc_model.state_dict(), filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear memory\n",
    "del model\n",
    "del unc_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Uncertainty Wrappers\n",
    "Evaluates prediction and uncertainty estimate on various datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading models\n",
      "loading model 0\n"
     ]
    }
   ],
   "source": [
    "from nn_ood.utils.test import process_datasets\n",
    "\n",
    "# LOAD UNC_WRAPPERS\n",
    "print(\"Loading models\")\n",
    "models = []\n",
    "for i in range(config.N_MODELS):\n",
    "    print(\"loading model %d\" % i)\n",
    "    filename = os.path.join(EXP_FOLDER, 'models', config.FILENAME + \"_%d\" % i)\n",
    "    state_dict = torch.load(filename)\n",
    "    model = config.make_model()\n",
    "    model.load_state_dict(state_dict)\n",
    "    model.eval()\n",
    "    model.to(config.device)\n",
    "    models.append(model)\n",
    "\n",
    "model = models[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test against OoD datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCOD (T=76,k=12)\n",
      "<class 'scod.sketching.sketched_pca.SinglePassPCA'>\n",
      "cifar10/models/scod_SRFT_s76_n12_model\n",
      "Testing val\n",
      "1000\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 667/1000 [00:51<00:31, 10.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [01:17<00:00, 12.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing ood\n",
      "1000\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [01:17<00:00, 12.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing svhn\n",
      "1000\n",
      "Using downloaded and verified file: /home/apoorva/datasets/SVHN/train_32x32.mat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [01:18<00:00, 12.75it/s]\n",
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing tIN\n",
      "1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [01:17<00:00, 12.95it/s]\n",
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing lsun\n",
      "1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [01:19<00:00, 12.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCOD (T=76,k=12) calibrated\n",
      "<class 'scod.sketching.sketched_pca.SinglePassPCA'>\n",
      "cifar10/models/scod_SRFT_s76_n12_calibrated_model\n",
      "Testing val\n",
      "1000\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [01:18<00:00, 12.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing ood\n",
      "1000\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [01:17<00:00, 12.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing svhn\n",
      "1000\n",
      "Using downloaded and verified file: /home/apoorva/datasets/SVHN/train_32x32.mat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [01:18<00:00, 12.76it/s]\n",
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing tIN\n",
      "1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [01:18<00:00, 12.67it/s]\n",
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing lsun\n",
      "1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [01:19<00:00, 12.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCOD_freeze_0.85 (T=184,k=30)\n",
      "0.85\n",
      "<class 'scod.sketching.sketched_pca.SinglePassPCA'>\n",
      "cifar10/models/scod_SRFT_s184_n30_freeze_0.85_model\n",
      "Testing val\n",
      "1000\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:26<00:00, 37.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing ood\n",
      "1000\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:27<00:00, 36.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing svhn\n",
      "1000\n",
      "Using downloaded and verified file: /home/apoorva/datasets/SVHN/train_32x32.mat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:26<00:00, 38.11it/s]\n",
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing tIN\n",
      "1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:26<00:00, 37.50it/s]\n",
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing lsun\n",
      "1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:27<00:00, 36.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCOD_freeze_0.85 (T=184,k=30) calibrated\n",
      "0.85\n",
      "<class 'scod.sketching.sketched_pca.SinglePassPCA'>\n",
      "cifar10/models/scod_SRFT_s184_n30_freeze_0.85_calibrated_model\n",
      "Testing val\n",
      "1000\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:25<00:00, 39.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing ood\n",
      "1000\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:26<00:00, 37.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing svhn\n",
      "1000\n",
      "Using downloaded and verified file: /home/apoorva/datasets/SVHN/train_32x32.mat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:26<00:00, 37.56it/s]\n",
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing tIN\n",
      "1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:26<00:00, 37.66it/s]\n",
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing lsun\n",
      "1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:26<00:00, 37.70it/s]\n"
     ]
    }
   ],
   "source": [
    "save_folder = os.path.join(EXP_FOLDER, 'results')\n",
    "if not os.path.exists(save_folder):\n",
    "    os.makedirs(save_folder)\n",
    "save_folder = os.path.join(EXP_FOLDER, 'times')\n",
    "if not os.path.exists(save_folder):\n",
    "    os.makedirs(save_folder)\n",
    "    \n",
    "for name, info in config.test_unc_models.items():\n",
    "    print(name)\n",
    "    \n",
    "    config.unfreeze_model(model)\n",
    "    if 'freeze' in info:\n",
    "        if type(info['freeze']) is bool:\n",
    "            freeze_frac = None\n",
    "        else:\n",
    "            freeze_frac = info['freeze']\n",
    "        config.freeze_model(model, freeze_frac=freeze_frac)        \n",
    "    \n",
    "    if 'apply_fn' is info:\n",
    "        model.apply(info['apply_fn'])\n",
    "        \n",
    "    if 'multi_model' in info:\n",
    "        unc_model = info['class'](models, config.dist_constructor, info['kwargs'])\n",
    "    else:\n",
    "        unc_model = info['class'](model, config.dist_constructor, info['kwargs'])\n",
    "    \n",
    "    if info['load_name'] is not None: \n",
    "        filename = os.path.join(EXP_FOLDER, \"models\", info['load_name']+\"_\"+config.FILENAME)\n",
    "        print(filename)\n",
    "        unc_model.load_state_dict(torch.load(filename))\n",
    "        unc_model.cuda()\n",
    "    \n",
    "    try:\n",
    "        cProfile.run(\"\"\"\\n\n",
    "results = process_datasets(config.dataset_class, \n",
    "                           config.test_dataset_args,\n",
    "                           unc_model, \n",
    "                           config.device,\n",
    "                           N=1000,\n",
    "                           **info['forward_kwargs'])\n",
    "        \"\"\", os.path.join(EXP_FOLDER, \"times\", name) )\n",
    "        savepath = os.path.join(EXP_FOLDER, \"results\", name)\n",
    "        torch.save(results, savepath)\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test against noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nn_ood.utils.test import transform_sweep\n",
    "\n",
    "if \"transforms\" not in dir(config):\n",
    "    raise NameError(\"No transforms to test for this experiment\")\n",
    "    \n",
    "save_folder = os.path.join(EXP_FOLDER, 'results_transforms')\n",
    "if not os.path.exists(save_folder):\n",
    "    os.makedirs(save_folder)\n",
    "save_folder = os.path.join(EXP_FOLDER, 'times_transforms')\n",
    "if not os.path.exists(save_folder):\n",
    "    os.makedirs(save_folder)\n",
    "    \n",
    "for name, info in config.test_unc_models.items():\n",
    "    print(name)\n",
    "    \n",
    "    config.unfreeze_model(model)\n",
    "    if 'freeze' in info:\n",
    "        if type(info['freeze']) is bool:\n",
    "            freeze_frac = None\n",
    "        else:\n",
    "            freeze_frac = info['freeze']\n",
    "        config.freeze_model(model, freeze_frac=freeze_frac)        \n",
    "    \n",
    "    if 'apply_fn' is info:\n",
    "        model.apply(info['apply_fn'])\n",
    "        \n",
    "    if 'multi_model' in info:\n",
    "        unc_model = info['class'](models, config.dist_constructor, info['kwargs'])\n",
    "    else:\n",
    "        unc_model = info['class'](model, config.dist_constructor, info['kwargs'])\n",
    "    \n",
    "    if info['load_name'] is not None: \n",
    "        filename = os.path.join(EXP_FOLDER, \"models\", info['load_name']+\"_\"+config.FILENAME)\n",
    "        print(filename)\n",
    "        unc_model.load_state_dict(torch.load(filename))\n",
    "        unc_model.cuda()\n",
    "    \n",
    "\n",
    "    dataset = config.dataset_class(config.in_dist_splits[0],N=1000)\n",
    "    cProfile.run(\"\"\"\\n\n",
    "results = transform_sweep(dataset, \n",
    "                      config.transforms,\n",
    "                      unc_model, \n",
    "                      config.device,\n",
    "                      **info['forward_kwargs'])\n",
    "    \"\"\", os.path.join(EXP_FOLDER, \"times\", name) )\n",
    "    savepath = os.path.join(EXP_FOLDER, \"results\", name)\n",
    "    torch.save(results, savepath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
